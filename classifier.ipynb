{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# Batch training because computing gradients over the entire dataset is computationally expensive\n",
    "# as we compute average gradient over all samples\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Use MPS for Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # Use CUDA for NVIDIA GPUs\n",
    "else:\n",
    "    device = torch.device('cpu')  # Fallback to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    # converts images to PyTorch tensors and scales pixel values to [0, 1].\n",
    "    transforms.ToTensor(),\n",
    "    # normalise using mean = 0.5 and st_dev = 0.5 with z-score formula (x - mean) / st_dev\n",
    "    # basically, x_normalised = 2x - 1 and remember all x's from ToTensor() are [0, 1]\n",
    "    # so we normalise all pixel values from [-1, 1].\n",
    "\n",
    "    # We do this because many activation functions (like tanh or ReLU) and optimization \n",
    "    # algorithms perform better when the input data is normalized and has a mean close to 0.\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Analysis\n",
    "train_dataset\n",
    "# num datapoints in 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000,\n",
       "           -1.0000, -0.8980, -0.4275, -1.0000, -1.0000, -0.9922, -0.9686,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.9922, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -1.0000,\n",
       "           -0.7176,  0.0667, -0.0039, -0.5137, -0.5765, -1.0000, -1.0000,\n",
       "           -1.0000, -0.9922, -0.9765, -0.9686, -1.0000, -1.0000, -0.9765],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -1.0000,\n",
       "           -0.2000,  0.6000,  0.3804,  0.0510,  0.1294, -0.0353, -0.8196,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9059, -0.9216, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            0.2157,  0.8510,  0.6235,  0.3961, -0.1608,  0.2235,  0.2627,\n",
       "           -0.1451, -0.4980, -0.8196, -0.3961,  0.0196, -0.4353, -0.8824],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -0.4588,\n",
       "            0.6235,  0.7490,  0.7098,  0.6941,  0.6941,  0.2784, -0.0039,\n",
       "           -0.0510, -0.0431,  0.1451,  0.1059, -0.3098,  0.3490, -0.4824],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.9922, -0.9922, -0.9922, -1.0000,  0.5686,\n",
       "            0.8196,  0.8196,  0.8275,  0.7961,  0.7490,  0.7490,  0.6863,\n",
       "            0.6706,  0.2863, -0.0039, -0.0353,  0.5373,  0.7961, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4353,\n",
       "            0.7647,  0.6941,  0.7490,  0.7882,  0.8431,  0.7804,  0.7569,\n",
       "            0.7412,  0.7569,  0.7333,  0.7490,  0.9216,  0.3569, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5137,\n",
       "            0.7882,  0.7098,  0.6706,  0.5529,  0.4118,  0.6627,  0.6471,\n",
       "            0.6549,  0.6706,  0.7490,  0.7255,  0.9059,  0.5843, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.9922, -0.9765, -1.0000, -0.9059,  0.7176,\n",
       "            0.7255,  0.6627,  0.7098,  0.5059,  0.3255,  0.7804,  0.6314,\n",
       "            0.7098,  0.7569,  0.6627,  0.7725,  0.5451,  0.6392, -0.5922],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.9529, -1.0000, -0.2235,  0.9137,\n",
       "            0.7412,  0.7255,  0.7098,  0.5922,  0.5529,  0.7333,  0.6863,\n",
       "            0.6706,  0.7412,  0.7255,  0.9216, -0.0667,  0.3098, -0.5608],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.9686, -1.0000, -1.0000, -0.5686,  0.8510,\n",
       "            0.7882,  0.8039,  0.7882,  0.8824,  0.8196,  0.6706,  0.7098,\n",
       "            0.7490,  0.8353,  0.7020,  0.7020,  0.6392, -0.2784, -1.0000],\n",
       "          [-1.0000, -1.0000, -0.9922, -0.9686, -0.9529, -0.9451, -0.9843,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8588,  0.7725,\n",
       "            0.7020,  0.7490,  0.7412,  0.7176,  0.7412,  0.7333,  0.6941,\n",
       "            0.7490,  0.7961,  0.6863,  0.7098,  1.0000, -0.3961, -1.0000],\n",
       "          [-1.0000, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.5137,  0.1373,  0.6000,  0.7882,  0.6235,\n",
       "            0.6706,  0.7333,  0.7098,  0.6314,  0.6549,  0.7098,  0.7569,\n",
       "            0.7490,  0.7176,  0.6863,  0.7569,  0.9137,  0.2471, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.6549, -0.3569,\n",
       "           -0.1608,  0.4824,  0.7882,  0.7255,  0.7412,  0.7020,  0.7725,\n",
       "            0.5686,  0.6078,  0.6549,  0.8039,  0.7569,  0.8353,  0.3804,\n",
       "            0.4745,  0.9608,  0.9451,  0.8275,  0.8667,  0.6863, -1.0000],\n",
       "          [-1.0000, -0.5529,  0.4667,  0.6314,  0.7569,  0.7333,  0.7569,\n",
       "            0.6314,  0.6000,  0.6784,  0.6314,  0.6392,  0.5686,  0.2471,\n",
       "            0.9216,  0.5137,  0.6157,  0.7490,  1.0000,  1.0000,  0.7333,\n",
       "            0.8353,  0.7333,  0.6549,  0.7255,  0.8196,  0.9294, -1.0000],\n",
       "          [-0.9765,  0.5843,  0.7882,  0.7569,  0.7333,  0.6549,  0.6549,\n",
       "            0.6784,  0.6078,  0.6078,  0.6078,  0.7255,  0.8824, -0.3725,\n",
       "            0.1765,  1.0000,  0.7961,  0.7333,  0.4745,  0.2078,  0.4980,\n",
       "            0.6471,  0.6000,  0.6392,  0.7412,  0.7882,  0.7647, -1.0000],\n",
       "          [-0.2314,  0.8275,  0.5529,  0.6471,  0.7412,  0.7961,  0.7961,\n",
       "            0.8353,  0.9529,  0.7255,  0.5216,  0.6863,  0.7020,  0.8902,\n",
       "           -0.4902, -0.4275, -0.1686, -0.0824,  0.3176,  0.7176,  0.7333,\n",
       "            0.6863,  0.7020,  0.7490,  0.7490,  0.7569,  0.7961, -0.7725],\n",
       "          [-0.4118,  0.6000,  0.6627,  0.6000,  0.5137,  0.6078,  0.6549,\n",
       "            0.7647,  0.6941,  0.4510,  0.5451,  0.6157,  0.5529,  0.6706,\n",
       "            0.8824,  0.5294,  0.7804,  0.9216,  0.8745,  0.7490,  0.7098,\n",
       "            0.6627,  0.6392,  0.7412,  0.7255,  0.7333,  0.8039, -0.4745],\n",
       "          [-0.6235,  0.5922,  0.4353,  0.5216,  0.6706,  0.5451,  0.4510,\n",
       "            0.4902,  0.5216,  0.5059,  0.5843,  0.6784,  0.7176,  0.7333,\n",
       "            0.7255,  0.8510,  0.7647,  0.6941,  0.5608,  0.6157,  0.4588,\n",
       "            0.4196,  0.3882,  0.3490,  0.4196,  0.6078,  0.6157, -0.0980],\n",
       "          [-1.0000, -0.0431,  0.7176,  0.5137,  0.4039,  0.3412,  0.4353,\n",
       "            0.5373,  0.6000,  0.6471,  0.6706,  0.6235,  0.6549,  0.6471,\n",
       "            0.5686,  0.5373,  0.5216,  0.4980,  0.5294,  0.4980,  0.5529,\n",
       "            0.5059,  0.3804,  0.2235,  0.3098,  0.3882,  0.6471, -0.2784],\n",
       "          [-1.0000, -1.0000, -0.4196,  0.4824,  0.6627,  0.4980,  0.3725,\n",
       "            0.3490,  0.3725,  0.4196,  0.4510,  0.4745,  0.4824,  0.4745,\n",
       "            0.5137,  0.5529,  0.6000,  0.6392,  0.6471,  0.6471,  0.6549,\n",
       "            0.4745,  0.4745,  0.5216,  0.5059,  0.6941,  0.3333, -1.0000],\n",
       "          [-0.9843, -1.0000, -1.0000, -1.0000, -0.4824,  0.5686,  0.7412,\n",
       "            0.8588,  0.8745,  0.8980,  0.9294,  0.9059,  0.9137,  0.7333,\n",
       "            0.7255,  0.5137,  0.4980,  0.4039,  0.4275,  0.4275,  0.4196,\n",
       "            0.3804,  0.3020,  0.3176, -0.2235, -0.5451, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.6863, -0.5216, -0.6549, -0.4353, -0.6784, -0.7255, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuple of Data and Target\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000,\n",
       "          -1.0000, -0.8980, -0.4275, -1.0000, -1.0000, -0.9922, -0.9686,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.9922, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -1.0000,\n",
       "          -0.7176,  0.0667, -0.0039, -0.5137, -0.5765, -1.0000, -1.0000,\n",
       "          -1.0000, -0.9922, -0.9765, -0.9686, -1.0000, -1.0000, -0.9765],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -1.0000,\n",
       "          -0.2000,  0.6000,  0.3804,  0.0510,  0.1294, -0.0353, -0.8196,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9059, -0.9216, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           0.2157,  0.8510,  0.6235,  0.3961, -0.1608,  0.2235,  0.2627,\n",
       "          -0.1451, -0.4980, -0.8196, -0.3961,  0.0196, -0.4353, -0.8824],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -0.4588,\n",
       "           0.6235,  0.7490,  0.7098,  0.6941,  0.6941,  0.2784, -0.0039,\n",
       "          -0.0510, -0.0431,  0.1451,  0.1059, -0.3098,  0.3490, -0.4824],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.9922, -0.9922, -0.9922, -1.0000,  0.5686,\n",
       "           0.8196,  0.8196,  0.8275,  0.7961,  0.7490,  0.7490,  0.6863,\n",
       "           0.6706,  0.2863, -0.0039, -0.0353,  0.5373,  0.7961, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4353,\n",
       "           0.7647,  0.6941,  0.7490,  0.7882,  0.8431,  0.7804,  0.7569,\n",
       "           0.7412,  0.7569,  0.7333,  0.7490,  0.9216,  0.3569, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5137,\n",
       "           0.7882,  0.7098,  0.6706,  0.5529,  0.4118,  0.6627,  0.6471,\n",
       "           0.6549,  0.6706,  0.7490,  0.7255,  0.9059,  0.5843, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.9922, -0.9765, -1.0000, -0.9059,  0.7176,\n",
       "           0.7255,  0.6627,  0.7098,  0.5059,  0.3255,  0.7804,  0.6314,\n",
       "           0.7098,  0.7569,  0.6627,  0.7725,  0.5451,  0.6392, -0.5922],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.9529, -1.0000, -0.2235,  0.9137,\n",
       "           0.7412,  0.7255,  0.7098,  0.5922,  0.5529,  0.7333,  0.6863,\n",
       "           0.6706,  0.7412,  0.7255,  0.9216, -0.0667,  0.3098, -0.5608],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.9686, -1.0000, -1.0000, -0.5686,  0.8510,\n",
       "           0.7882,  0.8039,  0.7882,  0.8824,  0.8196,  0.6706,  0.7098,\n",
       "           0.7490,  0.8353,  0.7020,  0.7020,  0.6392, -0.2784, -1.0000],\n",
       "         [-1.0000, -1.0000, -0.9922, -0.9686, -0.9529, -0.9451, -0.9843,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8588,  0.7725,\n",
       "           0.7020,  0.7490,  0.7412,  0.7176,  0.7412,  0.7333,  0.6941,\n",
       "           0.7490,  0.7961,  0.6863,  0.7098,  1.0000, -0.3961, -1.0000],\n",
       "         [-1.0000, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.5137,  0.1373,  0.6000,  0.7882,  0.6235,\n",
       "           0.6706,  0.7333,  0.7098,  0.6314,  0.6549,  0.7098,  0.7569,\n",
       "           0.7490,  0.7176,  0.6863,  0.7569,  0.9137,  0.2471, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.6549, -0.3569,\n",
       "          -0.1608,  0.4824,  0.7882,  0.7255,  0.7412,  0.7020,  0.7725,\n",
       "           0.5686,  0.6078,  0.6549,  0.8039,  0.7569,  0.8353,  0.3804,\n",
       "           0.4745,  0.9608,  0.9451,  0.8275,  0.8667,  0.6863, -1.0000],\n",
       "         [-1.0000, -0.5529,  0.4667,  0.6314,  0.7569,  0.7333,  0.7569,\n",
       "           0.6314,  0.6000,  0.6784,  0.6314,  0.6392,  0.5686,  0.2471,\n",
       "           0.9216,  0.5137,  0.6157,  0.7490,  1.0000,  1.0000,  0.7333,\n",
       "           0.8353,  0.7333,  0.6549,  0.7255,  0.8196,  0.9294, -1.0000],\n",
       "         [-0.9765,  0.5843,  0.7882,  0.7569,  0.7333,  0.6549,  0.6549,\n",
       "           0.6784,  0.6078,  0.6078,  0.6078,  0.7255,  0.8824, -0.3725,\n",
       "           0.1765,  1.0000,  0.7961,  0.7333,  0.4745,  0.2078,  0.4980,\n",
       "           0.6471,  0.6000,  0.6392,  0.7412,  0.7882,  0.7647, -1.0000],\n",
       "         [-0.2314,  0.8275,  0.5529,  0.6471,  0.7412,  0.7961,  0.7961,\n",
       "           0.8353,  0.9529,  0.7255,  0.5216,  0.6863,  0.7020,  0.8902,\n",
       "          -0.4902, -0.4275, -0.1686, -0.0824,  0.3176,  0.7176,  0.7333,\n",
       "           0.6863,  0.7020,  0.7490,  0.7490,  0.7569,  0.7961, -0.7725],\n",
       "         [-0.4118,  0.6000,  0.6627,  0.6000,  0.5137,  0.6078,  0.6549,\n",
       "           0.7647,  0.6941,  0.4510,  0.5451,  0.6157,  0.5529,  0.6706,\n",
       "           0.8824,  0.5294,  0.7804,  0.9216,  0.8745,  0.7490,  0.7098,\n",
       "           0.6627,  0.6392,  0.7412,  0.7255,  0.7333,  0.8039, -0.4745],\n",
       "         [-0.6235,  0.5922,  0.4353,  0.5216,  0.6706,  0.5451,  0.4510,\n",
       "           0.4902,  0.5216,  0.5059,  0.5843,  0.6784,  0.7176,  0.7333,\n",
       "           0.7255,  0.8510,  0.7647,  0.6941,  0.5608,  0.6157,  0.4588,\n",
       "           0.4196,  0.3882,  0.3490,  0.4196,  0.6078,  0.6157, -0.0980],\n",
       "         [-1.0000, -0.0431,  0.7176,  0.5137,  0.4039,  0.3412,  0.4353,\n",
       "           0.5373,  0.6000,  0.6471,  0.6706,  0.6235,  0.6549,  0.6471,\n",
       "           0.5686,  0.5373,  0.5216,  0.4980,  0.5294,  0.4980,  0.5529,\n",
       "           0.5059,  0.3804,  0.2235,  0.3098,  0.3882,  0.6471, -0.2784],\n",
       "         [-1.0000, -1.0000, -0.4196,  0.4824,  0.6627,  0.4980,  0.3725,\n",
       "           0.3490,  0.3725,  0.4196,  0.4510,  0.4745,  0.4824,  0.4745,\n",
       "           0.5137,  0.5529,  0.6000,  0.6392,  0.6471,  0.6471,  0.6549,\n",
       "           0.4745,  0.4745,  0.5216,  0.5059,  0.6941,  0.3333, -1.0000],\n",
       "         [-0.9843, -1.0000, -1.0000, -1.0000, -0.4824,  0.5686,  0.7412,\n",
       "           0.8588,  0.8745,  0.8980,  0.9294,  0.9059,  0.9137,  0.7333,\n",
       "           0.7255,  0.5137,  0.4980,  0.4039,  0.4275,  0.4275,  0.4196,\n",
       "           0.3804,  0.3020,  0.3176, -0.2235, -0.5451, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6863, -0.5216, -0.6549, -0.4353, -0.6784, -0.7255, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Shape\n",
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels\n",
    "labels = train_dataset.targets\n",
    "\n",
    "# Find the unique classes\n",
    "num_classes = len(torch.unique(labels))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Data Analysis we have 60,000 28x28 images in the training set, this allows us to make our neural network\n",
    "# Make the Neural Network\n",
    "class FashionMNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTClassifier, self).__init__()\n",
    "        # Define layers explicitly\n",
    "        # From Tensor of Shape (28, 28) to (28 * 28,)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # To lower dimensional representation\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # We have 10 clases in the dataset\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces 14x14 -> 7x7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for FashionMNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer - what actually updates weights\n",
    "model = FashionMNISTClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for imgs, targets in loader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4937\n",
      "Epoch [2/10], Loss: 0.3679\n",
      "Epoch [3/10], Loss: 0.3280\n",
      "Epoch [4/10], Loss: 0.3050\n",
      "Epoch [5/10], Loss: 0.2851\n",
      "Epoch [6/10], Loss: 0.2676\n",
      "Epoch [7/10], Loss: 0.2539\n",
      "Epoch [8/10], Loss: 0.2435\n",
      "Epoch [9/10], Loss: 0.2313\n",
      "Epoch [10/10], Loss: 0.2198\n",
      "Accuracy: 87.43%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-13.9600, -12.3344, -16.6090, -12.6213, -15.9972,  -0.1711, -14.2693,\n",
       "           1.5492, -12.8284,   6.5383]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(test_dataset[0][0].to(device))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(prediction).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdUElEQVR4nO3db2yV9f3/8ddpKYd/7altaU+P/LH8EYxAl6F0HcpUGkq3GBFuqPMGGqLBFTNk6sIyQbdlnSxxxoXpbiwwM1FnMmCaSILVlmwrGFBCzEZDSZUibZlozymtbbH9/G7ws98d+fu5OO27Lc9H8knoOde717tXr/bFOefq+4Scc04AAAyyNOsGAABXJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJkZZN/BNfX19OnHihDIzMxUKhazbAQB4cs6pvb1dsVhMaWkXfpwz5ALoxIkTmjx5snUbAIAr1NTUpEmTJl3w/iH3FFxmZqZ1CwCAFLjU7/MBC6DNmzfruuuu05gxY1RSUqL333//sup42g0ARoZL/T4fkAB6/fXXtW7dOm3cuFEffPCBiouLVV5erpMnTw7E7gAAw5EbAAsWLHCVlZX9H/f29rpYLOaqqqouWRuPx50kFovFYg3zFY/HL/r7PuWPgHp6enTgwAGVlZX135aWlqaysjLV1dWds313d7cSiUTSAgCMfCkPoM8++0y9vb0qKChIur2goEAtLS3nbF9VVaVIJNK/uAIOAK4O5lfBrV+/XvF4vH81NTVZtwQAGAQp/zugvLw8paenq7W1Nen21tZWRaPRc7YPh8MKh8OpbgMAMMSl/BHQ6NGjNX/+fFVXV/ff1tfXp+rqapWWlqZ6dwCAYWpAJiGsW7dOK1eu1E033aQFCxbo+eefV0dHhx588MGB2B0AYBgakAC655579N///lcbNmxQS0uLvvWtb2nXrl3nXJgAALh6hZxzzrqJ/5VIJBSJRKzbAABcoXg8rqysrAveb34VHADg6kQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATKQ+gp59+WqFQKGnNnj071bsBAAxzowbik95444165513/m8nowZkNwCAYWxAkmHUqFGKRqMD8akBACPEgLwGdOTIEcViMU2bNk3333+/jh07dsFtu7u7lUgkkhYAYORLeQCVlJRo69at2rVrl1588UU1Njbq1ltvVXt7+3m3r6qqUiQS6V+TJ09OdUsAgCEo5JxzA7mDtrY2TZ06Vc8995xWrVp1zv3d3d3q7u7u/ziRSBBCADACxONxZWVlXfD+Ab86IDs7W9dff70aGhrOe384HFY4HB7oNgAAQ8yA/x3Q6dOndfToURUWFg70rgAAw0jKA+jxxx9XbW2tPv74Y/3rX//S3XffrfT0dN13332p3hUAYBhL+VNwx48f13333adTp05p4sSJuuWWW7R3715NnDgx1bsCAAxjA34Rgq9EIqFIJGLdBgDgCl3qIgRmwQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAx4G9IBwAXkp6e7l3T19fnXTOYM5eDvMHm/74r9OWaMWOGd42kC745qAUeAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDANG7hCoVBoUGqCTIG+9tprvWskqbS01Lvm7bff9q7p6Ojwrhnqgky2DmLFihWB6p599tkUdxIcj4AAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYBgpYCDIYNEgbr311kB1JSUl3jWxWMy75oUXXvCuGery8/O9a8rLy71rEomEd81QwyMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJhhGClyh9PR075qvvvrKu+amm27yrrnhhhu8aySptbXVu2bmzJneNdu3b/eu+fzzz71rxo4d610jSZ988ol3TW5urndNVlaWd83x48e9a4YaHgEBAEwQQAAAE94BtGfPHt15552KxWIKhULasWNH0v3OOW3YsEGFhYUaO3asysrKdOTIkVT1CwAYIbwDqKOjQ8XFxdq8efN579+0aZNeeOEFvfTSS9q3b5/Gjx+v8vJydXV1XXGzAICRw/sihIqKClVUVJz3Puecnn/+ef385z/XXXfdJUl6+eWXVVBQoB07dujee++9sm4BACNGSl8DamxsVEtLi8rKyvpvi0QiKikpUV1d3Xlruru7lUgkkhYAYORLaQC1tLRIkgoKCpJuLygo6L/vm6qqqhSJRPrX5MmTU9kSAGCIMr8Kbv369YrH4/2rqanJuiUAwCBIaQBFo1FJ5/4RW2tra/993xQOh5WVlZW0AAAjX0oDqKioSNFoVNXV1f23JRIJ7du3T6WlpancFQBgmPO+Cu706dNqaGjo/7ixsVEHDx5UTk6OpkyZorVr1+pXv/qVZs6cqaKiIj311FOKxWJatmxZKvsGAAxz3gG0f/9+3X777f0fr1u3TpK0cuVKbd26VU8++aQ6Ojr08MMPq62tTbfccot27dqlMWPGpK5rAMCwF3LOOesm/lcikVAkErFuA1eptDT/Z6X7+vq8a8aPH+9ds2HDBu+a7u5u7xop2Nd03XXXeddkZ2d713zxxRfeNUH/Axzk+xTkQqog513Q7+3atWsD1QURj8cv+rq++VVwAICrEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAhPfbMWBoC4VC3jVBB6IHmeAbZF9BatLT071rJKm3tzdQna/Vq1d717S0tHjXdHV1eddIwSZbB5k4/c13T74cQb63QaZ7S1JHR4d3TU9Pj3dNkHeCDofD3jVSsAnfQY7D5eAREADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMMIx0kgzUkNOhg0SCCDnj0FWT45GANFZWk++67z7smGo1613zwwQfeNRkZGd41kpSdne1dc+rUKe+azz//3LsmLy/PuyYzM9O7Rgo+1NZXkMG+48aNC7SvmTNnetccPHgw0L4uhUdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDCMdJAM1pDQIEMNg9RIwQZ+BjkOgzlY9MEHH/SumTVrlndNU1OTd02QIZxBhuBK0tixY71rPv30U++aIENCgwzB7ezs9K6RpDFjxnjXDNbg4aDKy8u9axhGCgAYUQggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJi4qoeRBh3CGUSQYYNBhhoGGdQYpGYwxWIx75rly5cH2leQIZxHjhzxrpkwYYJ3TTgc9q7Jzc31rpGknp4e75og5/i4ceO8a4IIOtC2u7t7UPbV0dHhXRP053bhwoWB6gYCj4AAACYIIACACe8A2rNnj+68807FYjGFQiHt2LEj6f4HHnhAoVAoaS1dujRV/QIARgjvAOro6FBxcbE2b958wW2WLl2q5ubm/vXqq69eUZMAgJHH+yKEiooKVVRUXHSbcDisaDQauCkAwMg3IK8B1dTUKD8/X7NmzdIjjzyiU6dOXXDb7u5uJRKJpAUAGPlSHkBLly7Vyy+/rOrqaj377LOqra1VRUXFBS9NrKqqUiQS6V+TJ09OdUsAgCEo5X8HdO+99/b/e+7cuZo3b56mT5+umpoaLV68+Jzt169fr3Xr1vV/nEgkCCEAuAoM+GXY06ZNU15enhoaGs57fzgcVlZWVtICAIx8Ax5Ax48f16lTp1RYWDjQuwIADCPeT8GdPn066dFMY2OjDh48qJycHOXk5OiZZ57RihUrFI1GdfToUT355JOaMWOGysvLU9o4AGB48w6g/fv36/bbb+//+OvXb1auXKkXX3xRhw4d0p///Ge1tbUpFotpyZIl+uUvfxlojhUAYOQKuSATBAdQIpFQJBJRWlqa1zDOoMMGIU2cODFQ3dSpU71rZs+e7V0T5OnbIMM0Jamrq8u7Jshg0SCvdWZkZHjXBBmuKknjx48flJogX1NbW5t3TdDfD+np6d41QQaLnjlzxrsmyHknSZFIxLvm17/+tdf2vb29Onz4sOLx+EXPdWbBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMpPwtuVOlr69vwPdRUFAQqC7IFOjBmi4cZPpxUVGRd40kjRs3zrsmyNTf06dPe9ekpQX7v1WQScFBjvlXX33lXRPkeHd2dnrXSFJ3d7d3zejRo71rmpubvWuCfI+CHDtJ+uKLL7xrgkypvuaaa7xrgkzdlqRoNOpdk5ub67X95Z7fPAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgYsgOI/VVVlbmXROLxQLtK8hAzfz8fO+aIAM1gwxxDfL1SFJ7e7t3TZBBjUGGJ4ZCIe8aSQqHw941QQZWBvneBjl26enp3jVSsEGXQc6HeDzuXRPkZ2kwBTkfgvzcBhmCKwUbGus7PJdhpACAIY0AAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJITuM9I477tCoUZff3qpVq7z3cfjwYe8aSWpubvauSSQS3jVBBkn29PQMyn6CCjKwMsjwxN7eXu8aScrKyvKuCTL4NMggySADKzMyMrxrpGADYAsKCrxrbrzxRu+aIF/TYJ7jQQa5jhs3zrumq6vLu0YK1t/Jkye9tr/cc5VHQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwM2WGkBw4c8Bry+J3vfMd7H3PnzvWukaSFCxcGqvP11VdfedcEGfb5+eefe9cErYvH4941QYaRBhkQKkm5ubneNbNmzfKuCTJ8MsigVOecd40kFRcXe9ccOnTIu+bjjz/2rikrK/OuCYfD3jVS8OPnK8jP+qeffhpoX0EGI0+YMMFr+8sdBswjIACACQIIAGDCK4Cqqqp08803KzMzU/n5+Vq2bJnq6+uTtunq6lJlZaVyc3M1YcIErVixQq2trSltGgAw/HkFUG1trSorK7V3717t3r1bZ86c0ZIlS5Le4Oixxx7Tm2++qTfeeEO1tbU6ceKEli9fnvLGAQDDm9dFCLt27Ur6eOvWrcrPz9eBAwe0aNEixeNx/elPf9K2bdt0xx13SJK2bNmiG264QXv37g10oQAAYGS6oteAvr6iKScnR9LZK9fOnDmTdJXK7NmzNWXKFNXV1Z33c3R3dyuRSCQtAMDIFziA+vr6tHbtWi1cuFBz5syRJLW0tGj06NHKzs5O2ragoEAtLS3n/TxVVVWKRCL9a/LkyUFbAgAMI4EDqLKyUh999JFee+21K2pg/fr1isfj/aupqemKPh8AYHgI9Ieoa9as0VtvvaU9e/Zo0qRJ/bdHo1H19PSora0t6VFQa2urotHoeT9XOBwO/EdiAIDhy+sRkHNOa9as0fbt2/Xuu++qqKgo6f758+crIyND1dXV/bfV19fr2LFjKi0tTU3HAIARwesRUGVlpbZt26adO3cqMzOz/3WdSCSisWPHKhKJaNWqVVq3bp1ycnKUlZWlRx99VKWlpVwBBwBI4hVAL774oiTptttuS7p9y5YteuCBByRJv/vd75SWlqYVK1aou7tb5eXl+sMf/pCSZgEAI0fIDda0vcuUSCQUiUSs27go38F8klRSUuJdc/3113vXfPe73/Wuyc/P966Rgg3HHD9+vHdNkMGiQU/rvr4+75ogQ1kPHz7sXbN7927vmrffftu7Rjo70WSo+vvf/+5dM2XKlED7+uyzz7xrggwEDlITZICpdPZPX3w9/vjjXts759TZ2al4PH7R3xPMggMAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAaNgBgQDANGwAwJBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEx4BVBVVZVuvvlmZWZmKj8/X8uWLVN9fX3SNrfddptCoVDSWr16dUqbBgAMf14BVFtbq8rKSu3du1e7d+/WmTNntGTJEnV0dCRt99BDD6m5ubl/bdq0KaVNAwCGv1E+G+/atSvp461btyo/P18HDhzQokWL+m8fN26cotFoajoEAIxIV/QaUDwelyTl5OQk3f7KK68oLy9Pc+bM0fr169XZ2XnBz9Hd3a1EIpG0AABXARdQb2+v+8EPfuAWLlyYdPsf//hHt2vXLnfo0CH3l7/8xV177bXu7rvvvuDn2bhxo5PEYrFYrBG24vH4RXMkcACtXr3aTZ061TU1NV10u+rqaifJNTQ0nPf+rq4uF4/H+1dTU5P5QWOxWCzWla9LBZDXa0BfW7Nmjd566y3t2bNHkyZNuui2JSUlkqSGhgZNnz79nPvD4bDC4XCQNgAAw5hXADnn9Oijj2r79u2qqalRUVHRJWsOHjwoSSosLAzUIABgZPIKoMrKSm3btk07d+5UZmamWlpaJEmRSERjx47V0aNHtW3bNn3/+99Xbm6uDh06pMcee0yLFi3SvHnzBuQLAAAMUz6v++gCz/Nt2bLFOefcsWPH3KJFi1xOTo4Lh8NuxowZ7oknnrjk84D/Kx6Pmz9vyWKxWKwrX5f63R/6/8EyZCQSCUUiEes2AABXKB6PKysr64L3MwsOAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBiyAWQc866BQBAClzq9/mQC6D29nbrFgAAKXCp3+chN8QecvT19enEiRPKzMxUKBRKui+RSGjy5MlqampSVlaWUYf2OA5ncRzO4jicxXE4aygcB+ec2tvbFYvFlJZ24cc5owaxp8uSlpamSZMmXXSbrKysq/oE+xrH4SyOw1kch7M4DmdZH4dIJHLJbYbcU3AAgKsDAQQAMDGsAigcDmvjxo0Kh8PWrZjiOJzFcTiL43AWx+Gs4XQchtxFCACAq8OwegQEABg5CCAAgAkCCABgggACAJgYNgG0efNmXXfddRozZoxKSkr0/vvvW7c06J5++mmFQqGkNXv2bOu2BtyePXt05513KhaLKRQKaceOHUn3O+e0YcMGFRYWauzYsSorK9ORI0dsmh1AlzoODzzwwDnnx9KlS22aHSBVVVW6+eablZmZqfz8fC1btkz19fVJ23R1damyslK5ubmaMGGCVqxYodbWVqOOB8blHIfbbrvtnPNh9erVRh2f37AIoNdff13r1q3Txo0b9cEHH6i4uFjl5eU6efKkdWuD7sYbb1Rzc3P/+sc//mHd0oDr6OhQcXGxNm/efN77N23apBdeeEEvvfSS9u3bp/Hjx6u8vFxdXV2D3OnAutRxkKSlS5cmnR+vvvrqIHY48Gpra1VZWam9e/dq9+7dOnPmjJYsWaKOjo7+bR577DG9+eabeuONN1RbW6sTJ05o+fLlhl2n3uUcB0l66KGHks6HTZs2GXV8AW4YWLBggausrOz/uLe318ViMVdVVWXY1eDbuHGjKy4utm7DlCS3ffv2/o/7+vpcNBp1v/3tb/tva2trc+Fw2L366qsGHQ6Obx4H55xbuXKlu+uuu0z6sXLy5EknydXW1jrnzn7vMzIy3BtvvNG/zX/+8x8nydXV1Vm1OeC+eRycc+573/ue+/GPf2zX1GUY8o+Aenp6dODAAZWVlfXflpaWprKyMtXV1Rl2ZuPIkSOKxWKaNm2a7r//fh07dsy6JVONjY1qaWlJOj8ikYhKSkquyvOjpqZG+fn5mjVrlh555BGdOnXKuqUBFY/HJUk5OTmSpAMHDujMmTNJ58Ps2bM1ZcqUEX0+fPM4fO2VV15RXl6e5syZo/Xr16uzs9OivQsacsNIv+mzzz5Tb2+vCgoKkm4vKCjQ4cOHjbqyUVJSoq1bt2rWrFlqbm7WM888o1tvvVUfffSRMjMzrdsz0dLSIknnPT++vu9qsXTpUi1fvlxFRUU6evSofvazn6miokJ1dXVKT0+3bi/l+vr6tHbtWi1cuFBz5syRdPZ8GD16tLKzs5O2Hcnnw/mOgyT98Ic/1NSpUxWLxXTo0CH99Kc/VX19vf72t78ZdptsyAcQ/k9FRUX/v+fNm6eSkhJNnTpVf/3rX7Vq1SrDzjAU3Hvvvf3/njt3rubNm6fp06erpqZGixcvNuxsYFRWVuqjjz66Kl4HvZgLHYeHH364/99z585VYWGhFi9erKNHj2r69OmD3eZ5Dfmn4PLy8pSenn7OVSytra2KRqNGXQ0N2dnZuv7669XQ0GDdipmvzwHOj3NNmzZNeXl5I/L8WLNmjd566y299957SW/fEo1G1dPTo7a2tqTtR+r5cKHjcD4lJSWSNKTOhyEfQKNHj9b8+fNVXV3df1tfX5+qq6tVWlpq2Jm906dP6+jRoyosLLRuxUxRUZGi0WjS+ZFIJLRv376r/vw4fvy4Tp06NaLOD+ec1qxZo+3bt+vdd99VUVFR0v3z589XRkZG0vlQX1+vY8eOjajz4VLH4XwOHjwoSUPrfLC+CuJyvPbaay4cDrutW7e6f//73+7hhx922dnZrqWlxbq1QfWTn/zE1dTUuMbGRvfPf/7TlZWVuby8PHfy5Enr1gZUe3u7+/DDD92HH37oJLnnnnvOffjhh+6TTz5xzjn3m9/8xmVnZ7udO3e6Q4cOubvuussVFRW5L7/80rjz1LrYcWhvb3ePP/64q6urc42Nje6dd95x3/72t93MmTNdV1eXdesp88gjj7hIJOJqampcc3Nz/+rs7OzfZvXq1W7KlCnu3Xffdfv373elpaWutLTUsOvUu9RxaGhocL/4xS/c/v37XWNjo9u5c6ebNm2aW7RokXHnyYZFADnn3O9//3s3ZcoUN3r0aLdgwQK3d+9e65YG3T333OMKCwvd6NGj3bXXXuvuuece19DQYN3WgHvvvfecpHPWypUrnXNnL8V+6qmnXEFBgQuHw27x4sWuvr7etukBcLHj0NnZ6ZYsWeImTpzoMjIy3NSpU91DDz004v6Tdr6vX5LbsmVL/zZffvml+9GPfuSuueYaN27cOHf33Xe75uZmu6YHwKWOw7Fjx9yiRYtcTk6OC4fDbsaMGe6JJ55w8XjctvFv4O0YAAAmhvxrQACAkYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ/wfS3ncBjBZLmwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise Image Data\n",
    "plt.imshow(test_dataset[0][0].squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label of Image\n",
    "label = test_dataset[0][1]\n",
    "train_dataset.classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = FashionMNISTCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2107\n",
      "Epoch [2/10], Loss: 0.2015\n",
      "Epoch [3/10], Loss: 0.1887\n",
      "Epoch [4/10], Loss: 0.1839\n",
      "Epoch [5/10], Loss: 0.1775\n",
      "Epoch [6/10], Loss: 0.1655\n",
      "Epoch [7/10], Loss: 0.1618\n",
      "Epoch [8/10], Loss: 0.1538\n",
      "Epoch [9/10], Loss: 0.1479\n",
      "Epoch [10/10], Loss: 0.1435\n",
      "Accuracy: 89.09%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0333,  0.0293,  0.0799, -0.1019, -0.0356,  0.0229,  0.0596,  0.0352,\n",
       "         -0.0360,  0.0054]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the image\n",
    "image = test_dataset[0][0]  # Get the first image from the test dataset\n",
    "image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "prediction_logits = model_cnn(image)  # Forward pass\n",
    "prediction_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "predicted_class = torch.argmax(prediction_logits).item()  # Get predicted class\n",
    "\n",
    "# Output the predicted class\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pullover'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe CNN classifier is very wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
